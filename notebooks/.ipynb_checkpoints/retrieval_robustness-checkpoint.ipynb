{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89467c4d-ceac-4f36-bae8-e15be39f145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "REPO_ROOT=os.path.dirname(os.path.abspath('.'))\n",
    "os.chdir(REPO_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c44e991-c1dc-416f-b2ea-356c2253e9e3",
   "metadata": {},
   "source": [
    "# prepare essential environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0dd5e54-d86a-4aae-8b95-52c909bf5009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /home/bangyang/anaconda3/envs/CARE/lib/python3.9/site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/bangyang/anaconda3/envs/CARE/lib/python3.9/site-packages (from seaborn) (1.26.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/bangyang/anaconda3/envs/CARE/lib/python3.9/site-packages (from seaborn) (2.1.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in /home/bangyang/anaconda3/envs/CARE/lib/python3.9/site-packages (from seaborn) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/bangyang/anaconda3/envs/CARE/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/bangyang/anaconda3/envs/CARE/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/bangyang/anaconda3/envs/CARE/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/bangyang/anaconda3/envs/CARE/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/bangyang/anaconda3/envs/CARE/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/bangyang/anaconda3/envs/CARE/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/bangyang/anaconda3/envs/CARE/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/bangyang/anaconda3/envs/CARE/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/bangyang/anaconda3/envs/CARE/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (6.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/bangyang/anaconda3/envs/CARE/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/bangyang/anaconda3/envs/CARE/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/bangyang/anaconda3/envs/CARE/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.3->seaborn) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/bangyang/anaconda3/envs/CARE/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9a5d69-755d-4b3e-a3b7-7e5cb36dea12",
   "metadata": {},
   "source": [
    "# using different ratio of training captions as the retrieval database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e046b0-d835-40a0-a986-8acf149b9769",
   "metadata": {},
   "source": [
    "## run CARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97e6efab-7bd5-4017-9adf-de3c3d855f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_r (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_R): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (predictor): Predictor(\n",
      "      (nets): ModuleList(\n",
      "        (0): Predictor_attribute(\n",
      "          (prj): Linear(in_features=2048, out_features=500, bias=True)\n",
      "        )\n",
      "        (1): SemanticContainer(\n",
      "          (attr_embs): NaiveEmbeddings(\n",
      "            (word_embeddings): Embedding(500, 512)\n",
      "            (position_embeddings): Embedding(30, 512)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (semantic2hidden): Linear(in_features=500, out_features=512, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 18218884\n",
      "Trainable Params: 18218884\n",
      "100%|███████████████████████████████████████████| 24/24 [00:39<00:00,  1.63s/it]\n",
      "Bleu_1: 0.850927\n",
      "Bleu_2: 0.731035\n",
      "Bleu_3: 0.603629\n",
      "Bleu_4: 0.482431\n",
      "METEOR: 0.311424\n",
      "ROUGE_L: 0.645272\n",
      "CIDEr: 0.572412\n",
      "Sum: 2.01154\n",
      "mAP: 0.512406\n",
      "seed: 0\n",
      "ave_length: 7.44716\n",
      "novel: 0.308027\n",
      "unique: 0.426421\n",
      "usage: 538\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_r (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_R): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (predictor): Predictor(\n",
      "      (nets): ModuleList(\n",
      "        (0): Predictor_attribute(\n",
      "          (prj): Linear(in_features=2048, out_features=500, bias=True)\n",
      "        )\n",
      "        (1): SemanticContainer(\n",
      "          (attr_embs): NaiveEmbeddings(\n",
      "            (word_embeddings): Embedding(500, 512)\n",
      "            (position_embeddings): Embedding(30, 512)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (semantic2hidden): Linear(in_features=500, out_features=512, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 18218884\n",
      "Trainable Params: 18218884\n",
      "100%|███████████████████████████████████████████| 24/24 [00:35<00:00,  1.49s/it]\n",
      "Bleu_1: 0.850615\n",
      "Bleu_2: 0.732268\n",
      "Bleu_3: 0.60442\n",
      "Bleu_4: 0.482761\n",
      "METEOR: 0.311486\n",
      "ROUGE_L: 0.649622\n",
      "CIDEr: 0.567057\n",
      "Sum: 2.01093\n",
      "mAP: 0.513378\n",
      "seed: 1\n",
      "ave_length: 7.36154\n",
      "novel: 0.304013\n",
      "unique: 0.416388\n",
      "usage: 520\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_r (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_R): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (predictor): Predictor(\n",
      "      (nets): ModuleList(\n",
      "        (0): Predictor_attribute(\n",
      "          (prj): Linear(in_features=2048, out_features=500, bias=True)\n",
      "        )\n",
      "        (1): SemanticContainer(\n",
      "          (attr_embs): NaiveEmbeddings(\n",
      "            (word_embeddings): Embedding(500, 512)\n",
      "            (position_embeddings): Embedding(30, 512)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (semantic2hidden): Linear(in_features=500, out_features=512, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 18218884\n",
      "Trainable Params: 18218884\n",
      "100%|███████████████████████████████████████████| 24/24 [00:37<00:00,  1.54s/it]\n",
      "Bleu_1: 0.847912\n",
      "Bleu_2: 0.727279\n",
      "Bleu_3: 0.599567\n",
      "Bleu_4: 0.478881\n",
      "METEOR: 0.308534\n",
      "ROUGE_L: 0.645322\n",
      "CIDEr: 0.564507\n",
      "Sum: 1.99725\n",
      "mAP: 0.513775\n",
      "seed: 2\n",
      "ave_length: 7.32007\n",
      "novel: 0.29699\n",
      "unique: 0.412709\n",
      "usage: 536\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_r (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_R): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (predictor): Predictor(\n",
      "      (nets): ModuleList(\n",
      "        (0): Predictor_attribute(\n",
      "          (prj): Linear(in_features=2048, out_features=500, bias=True)\n",
      "        )\n",
      "        (1): SemanticContainer(\n",
      "          (attr_embs): NaiveEmbeddings(\n",
      "            (word_embeddings): Embedding(500, 512)\n",
      "            (position_embeddings): Embedding(30, 512)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (semantic2hidden): Linear(in_features=500, out_features=512, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 18218884\n",
      "Trainable Params: 18218884\n",
      "100%|███████████████████████████████████████████| 24/24 [00:35<00:00,  1.49s/it]\n",
      "Bleu_1: 0.852\n",
      "Bleu_2: 0.733238\n",
      "Bleu_3: 0.605752\n",
      "Bleu_4: 0.483523\n",
      "METEOR: 0.312172\n",
      "ROUGE_L: 0.647508\n",
      "CIDEr: 0.567044\n",
      "Sum: 2.01025\n",
      "mAP: 0.512004\n",
      "seed: 3\n",
      "ave_length: 7.39666\n",
      "novel: 0.293645\n",
      "unique: 0.407692\n",
      "usage: 513\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_r (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_R): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (predictor): Predictor(\n",
      "      (nets): ModuleList(\n",
      "        (0): Predictor_attribute(\n",
      "          (prj): Linear(in_features=2048, out_features=500, bias=True)\n",
      "        )\n",
      "        (1): SemanticContainer(\n",
      "          (attr_embs): NaiveEmbeddings(\n",
      "            (word_embeddings): Embedding(500, 512)\n",
      "            (position_embeddings): Embedding(30, 512)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (semantic2hidden): Linear(in_features=500, out_features=512, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 18218884\n",
      "Trainable Params: 18218884\n",
      "100%|███████████████████████████████████████████| 24/24 [00:36<00:00,  1.54s/it]\n",
      "Bleu_1: 0.848737\n",
      "Bleu_2: 0.729364\n",
      "Bleu_3: 0.602307\n",
      "Bleu_4: 0.481725\n",
      "METEOR: 0.309739\n",
      "ROUGE_L: 0.645443\n",
      "CIDEr: 0.569466\n",
      "Sum: 2.00637\n",
      "mAP: 0.513059\n",
      "seed: 4\n",
      "ave_length: 7.38595\n",
      "novel: 0.310702\n",
      "unique: 0.42709\n",
      "usage: 537\n",
      "1\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_r (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_R): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (predictor): Predictor(\n",
      "      (nets): ModuleList(\n",
      "        (0): Predictor_attribute(\n",
      "          (prj): Linear(in_features=2048, out_features=500, bias=True)\n",
      "        )\n",
      "        (1): SemanticContainer(\n",
      "          (attr_embs): NaiveEmbeddings(\n",
      "            (word_embeddings): Embedding(500, 512)\n",
      "            (position_embeddings): Embedding(30, 512)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (semantic2hidden): Linear(in_features=500, out_features=512, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 18218884\n",
      "Trainable Params: 18218884\n",
      "100%|███████████████████████████████████████████| 24/24 [00:37<00:00,  1.55s/it]\n",
      "Bleu_1: 0.855042\n",
      "Bleu_2: 0.734102\n",
      "Bleu_3: 0.605515\n",
      "Bleu_4: 0.483099\n",
      "METEOR: 0.313268\n",
      "ROUGE_L: 0.64775\n",
      "CIDEr: 0.584316\n",
      "Sum: 2.02843\n",
      "mAP: 0.538876\n",
      "seed: 0\n",
      "ave_length: 7.56689\n",
      "novel: 0.32107\n",
      "unique: 0.447826\n",
      "usage: 544\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_r (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_R): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (predictor): Predictor(\n",
      "      (nets): ModuleList(\n",
      "        (0): Predictor_attribute(\n",
      "          (prj): Linear(in_features=2048, out_features=500, bias=True)\n",
      "        )\n",
      "        (1): SemanticContainer(\n",
      "          (attr_embs): NaiveEmbeddings(\n",
      "            (word_embeddings): Embedding(500, 512)\n",
      "            (position_embeddings): Embedding(30, 512)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (semantic2hidden): Linear(in_features=500, out_features=512, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 18218884\n",
      "Trainable Params: 18218884\n",
      "100%|███████████████████████████████████████████| 24/24 [00:36<00:00,  1.50s/it]\n",
      "Bleu_1: 0.856057\n",
      "Bleu_2: 0.736478\n",
      "Bleu_3: 0.607391\n",
      "Bleu_4: 0.484538\n",
      "METEOR: 0.314049\n",
      "ROUGE_L: 0.649606\n",
      "CIDEr: 0.580331\n",
      "Sum: 2.02852\n",
      "mAP: 0.5387\n",
      "seed: 1\n",
      "ave_length: 7.50301\n",
      "novel: 0.320401\n",
      "unique: 0.437458\n",
      "usage: 530\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_r (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_R): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (predictor): Predictor(\n",
      "      (nets): ModuleList(\n",
      "        (0): Predictor_attribute(\n",
      "          (prj): Linear(in_features=2048, out_features=500, bias=True)\n",
      "        )\n",
      "        (1): SemanticContainer(\n",
      "          (attr_embs): NaiveEmbeddings(\n",
      "            (word_embeddings): Embedding(500, 512)\n",
      "            (position_embeddings): Embedding(30, 512)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (semantic2hidden): Linear(in_features=500, out_features=512, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 18218884\n",
      "Trainable Params: 18218884\n",
      "100%|███████████████████████████████████████████| 24/24 [00:38<00:00,  1.62s/it]\n",
      "Bleu_1: 0.853273\n",
      "Bleu_2: 0.731485\n",
      "Bleu_3: 0.603004\n",
      "Bleu_4: 0.481138\n",
      "METEOR: 0.31175\n",
      "ROUGE_L: 0.648032\n",
      "CIDEr: 0.57984\n",
      "Sum: 2.02076\n",
      "mAP: 0.538846\n",
      "seed: 2\n",
      "ave_length: 7.42809\n",
      "novel: 0.313378\n",
      "unique: 0.434783\n",
      "usage: 536\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_r (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_R): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (predictor): Predictor(\n",
      "      (nets): ModuleList(\n",
      "        (0): Predictor_attribute(\n",
      "          (prj): Linear(in_features=2048, out_features=500, bias=True)\n",
      "        )\n",
      "        (1): SemanticContainer(\n",
      "          (attr_embs): NaiveEmbeddings(\n",
      "            (word_embeddings): Embedding(500, 512)\n",
      "            (position_embeddings): Embedding(30, 512)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (semantic2hidden): Linear(in_features=500, out_features=512, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 18218884\n",
      "Trainable Params: 18218884\n",
      "100%|███████████████████████████████████████████| 24/24 [00:37<00:00,  1.55s/it]\n",
      "Bleu_1: 0.856836\n",
      "Bleu_2: 0.737523\n",
      "Bleu_3: 0.609144\n",
      "Bleu_4: 0.486875\n",
      "METEOR: 0.314768\n",
      "ROUGE_L: 0.650107\n",
      "CIDEr: 0.579617\n",
      "Sum: 2.03137\n",
      "mAP: 0.538928\n",
      "seed: 3\n",
      "ave_length: 7.5204\n",
      "novel: 0.318395\n",
      "unique: 0.43913\n",
      "usage: 548\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_r (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_R): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (predictor): Predictor(\n",
      "      (nets): ModuleList(\n",
      "        (0): Predictor_attribute(\n",
      "          (prj): Linear(in_features=2048, out_features=500, bias=True)\n",
      "        )\n",
      "        (1): SemanticContainer(\n",
      "          (attr_embs): NaiveEmbeddings(\n",
      "            (word_embeddings): Embedding(500, 512)\n",
      "            (position_embeddings): Embedding(30, 512)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (semantic2hidden): Linear(in_features=500, out_features=512, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 18218884\n",
      "Trainable Params: 18218884\n",
      "100%|███████████████████████████████████████████| 24/24 [00:39<00:00,  1.64s/it]\n",
      "Bleu_1: 0.853254\n",
      "Bleu_2: 0.733308\n",
      "Bleu_3: 0.604341\n",
      "Bleu_4: 0.482295\n",
      "METEOR: 0.313307\n",
      "ROUGE_L: 0.648315\n",
      "CIDEr: 0.583199\n",
      "Sum: 2.02712\n",
      "mAP: 0.538849\n",
      "seed: 4\n",
      "ave_length: 7.55485\n",
      "novel: 0.337124\n",
      "unique: 0.461538\n",
      "usage: 548\n",
      "10\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_r (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_R): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (predictor): Predictor(\n",
      "      (nets): ModuleList(\n",
      "        (0): Predictor_attribute(\n",
      "          (prj): Linear(in_features=2048, out_features=500, bias=True)\n",
      "        )\n",
      "        (1): SemanticContainer(\n",
      "          (attr_embs): NaiveEmbeddings(\n",
      "            (word_embeddings): Embedding(500, 512)\n",
      "            (position_embeddings): Embedding(30, 512)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (semantic2hidden): Linear(in_features=500, out_features=512, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 18218884\n",
      "Trainable Params: 18218884\n",
      "100%|███████████████████████████████████████████| 24/24 [00:39<00:00,  1.65s/it]\n",
      "Bleu_1: 0.858806\n",
      "Bleu_2: 0.738575\n",
      "Bleu_3: 0.609269\n",
      "Bleu_4: 0.485379\n",
      "METEOR: 0.314629\n",
      "ROUGE_L: 0.650908\n",
      "CIDEr: 0.593992\n",
      "Sum: 2.04491\n",
      "mAP: 0.550686\n",
      "seed: 0\n",
      "ave_length: 7.599\n",
      "novel: 0.335786\n",
      "unique: 0.464883\n",
      "usage: 573\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_r (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_R): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (predictor): Predictor(\n",
      "      (nets): ModuleList(\n",
      "        (0): Predictor_attribute(\n",
      "          (prj): Linear(in_features=2048, out_features=500, bias=True)\n",
      "        )\n",
      "        (1): SemanticContainer(\n",
      "          (attr_embs): NaiveEmbeddings(\n",
      "            (word_embeddings): Embedding(500, 512)\n",
      "            (position_embeddings): Embedding(30, 512)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (semantic2hidden): Linear(in_features=500, out_features=512, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 18218884\n",
      "Trainable Params: 18218884\n",
      "100%|███████████████████████████████████████████| 24/24 [00:37<00:00,  1.55s/it]\n",
      "Bleu_1: 0.857972\n",
      "Bleu_2: 0.739315\n",
      "Bleu_3: 0.611098\n",
      "Bleu_4: 0.488822\n",
      "METEOR: 0.315172\n",
      "ROUGE_L: 0.652325\n",
      "CIDEr: 0.587681\n",
      "Sum: 2.044\n",
      "mAP: 0.550592\n",
      "seed: 1\n",
      "ave_length: 7.49565\n",
      "novel: 0.318395\n",
      "unique: 0.442809\n",
      "usage: 540\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_r (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_R): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (predictor): Predictor(\n",
      "      (nets): ModuleList(\n",
      "        (0): Predictor_attribute(\n",
      "          (prj): Linear(in_features=2048, out_features=500, bias=True)\n",
      "        )\n",
      "        (1): SemanticContainer(\n",
      "          (attr_embs): NaiveEmbeddings(\n",
      "            (word_embeddings): Embedding(500, 512)\n",
      "            (position_embeddings): Embedding(30, 512)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (semantic2hidden): Linear(in_features=500, out_features=512, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 18218884\n",
      "Trainable Params: 18218884\n",
      "100%|███████████████████████████████████████████| 24/24 [00:52<00:00,  2.17s/it]\n",
      "Bleu_1: 0.854107\n",
      "Bleu_2: 0.733324\n",
      "Bleu_3: 0.604892\n",
      "Bleu_4: 0.482874\n",
      "METEOR: 0.31192\n",
      "ROUGE_L: 0.648762\n",
      "CIDEr: 0.587546\n",
      "Sum: 2.0311\n",
      "mAP: 0.550984\n",
      "seed: 2\n",
      "ave_length: 7.43344\n",
      "novel: 0.314716\n",
      "unique: 0.440468\n",
      "usage: 567\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_r (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_R): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (predictor): Predictor(\n",
      "      (nets): ModuleList(\n",
      "        (0): Predictor_attribute(\n",
      "          (prj): Linear(in_features=2048, out_features=500, bias=True)\n",
      "        )\n",
      "        (1): SemanticContainer(\n",
      "          (attr_embs): NaiveEmbeddings(\n",
      "            (word_embeddings): Embedding(500, 512)\n",
      "            (position_embeddings): Embedding(30, 512)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (semantic2hidden): Linear(in_features=500, out_features=512, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 18218884\n",
      "Trainable Params: 18218884\n",
      "100%|███████████████████████████████████████████| 24/24 [00:50<00:00,  2.11s/it]\n",
      "Bleu_1: 0.858855\n",
      "Bleu_2: 0.738121\n",
      "Bleu_3: 0.608975\n",
      "Bleu_4: 0.486571\n",
      "METEOR: 0.314906\n",
      "ROUGE_L: 0.650454\n",
      "CIDEr: 0.582205\n",
      "Sum: 2.03414\n",
      "mAP: 0.551135\n",
      "seed: 3\n",
      "ave_length: 7.54883\n",
      "novel: 0.317391\n",
      "unique: 0.439465\n",
      "usage: 520\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_r (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_R): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (predictor): Predictor(\n",
      "      (nets): ModuleList(\n",
      "        (0): Predictor_attribute(\n",
      "          (prj): Linear(in_features=2048, out_features=500, bias=True)\n",
      "        )\n",
      "        (1): SemanticContainer(\n",
      "          (attr_embs): NaiveEmbeddings(\n",
      "            (word_embeddings): Embedding(500, 512)\n",
      "            (position_embeddings): Embedding(30, 512)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (semantic2hidden): Linear(in_features=500, out_features=512, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 18218884\n",
      "Trainable Params: 18218884\n",
      "100%|███████████████████████████████████████████| 24/24 [00:53<00:00,  2.23s/it]\n",
      "Bleu_1: 0.858187\n",
      "Bleu_2: 0.739402\n",
      "Bleu_3: 0.611718\n",
      "Bleu_4: 0.48948\n",
      "METEOR: 0.315457\n",
      "ROUGE_L: 0.65202\n",
      "CIDEr: 0.593556\n",
      "Sum: 2.05051\n",
      "mAP: 0.550691\n",
      "seed: 4\n",
      "ave_length: 7.5214\n",
      "novel: 0.331773\n",
      "unique: 0.462876\n",
      "usage: 580\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/retrieval_db_ratio.sh exps/MSRVTT/Transformer/CARE/base_ViT_VA_VAT 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f8a5d9-c4b6-43c9-b90b-4c5a75387674",
   "metadata": {},
   "source": [
    "# run PGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d10d5a39-238a-4577-9407-3f5258e2def7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "- Modify feats_t to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_t (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_T): Text_Embedder()\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (pointer): Pointer(\n",
      "      (attention): ScaledDotProductAttention(\n",
      "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (Wq): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (Wc): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 17190402\n",
      "Trainable Params: 17190402\n",
      "100%|███████████████████████████████████████████| 24/24 [00:50<00:00,  2.10s/it]\n",
      "Bleu_1: 0.826878\n",
      "Bleu_2: 0.703243\n",
      "Bleu_3: 0.576695\n",
      "Bleu_4: 0.456615\n",
      "METEOR: 0.299764\n",
      "ROUGE_L: 0.624783\n",
      "CIDEr: 0.484853\n",
      "Sum: 1.86601\n",
      "seed: 0\n",
      "ave_length: 7.38261\n",
      "novel: 0.207023\n",
      "unique: 0.309699\n",
      "usage: 392\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "- Modify feats_t to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_t (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_T): Text_Embedder()\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (pointer): Pointer(\n",
      "      (attention): ScaledDotProductAttention(\n",
      "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (Wq): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (Wc): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 17190402\n",
      "Trainable Params: 17190402\n",
      "100%|███████████████████████████████████████████| 24/24 [00:52<00:00,  2.17s/it]\n",
      "Bleu_1: 0.825787\n",
      "Bleu_2: 0.700748\n",
      "Bleu_3: 0.5728\n",
      "Bleu_4: 0.453498\n",
      "METEOR: 0.300841\n",
      "ROUGE_L: 0.625149\n",
      "CIDEr: 0.489424\n",
      "Sum: 1.86891\n",
      "seed: 3\n",
      "ave_length: 7.50803\n",
      "novel: 0.23612\n",
      "unique: 0.337124\n",
      "usage: 410\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "- Modify feats_t to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_t (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_T): Text_Embedder()\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (pointer): Pointer(\n",
      "      (attention): ScaledDotProductAttention(\n",
      "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (Wq): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (Wc): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 17190402\n",
      "Trainable Params: 17190402\n",
      "100%|███████████████████████████████████████████| 24/24 [00:57<00:00,  2.39s/it]\n",
      "Bleu_1: 0.828277\n",
      "Bleu_2: 0.700468\n",
      "Bleu_3: 0.572471\n",
      "Bleu_4: 0.452731\n",
      "METEOR: 0.30105\n",
      "ROUGE_L: 0.623029\n",
      "CIDEr: 0.47659\n",
      "Sum: 1.8534\n",
      "seed: 1\n",
      "ave_length: 7.50736\n",
      "novel: 0.2\n",
      "unique: 0.298997\n",
      "usage: 355\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "- Modify feats_t to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_t (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_T): Text_Embedder()\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (pointer): Pointer(\n",
      "      (attention): ScaledDotProductAttention(\n",
      "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (Wq): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (Wc): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 17190402\n",
      "Trainable Params: 17190402\n",
      "100%|███████████████████████████████████████████| 24/24 [00:52<00:00,  2.19s/it]\n",
      "Bleu_1: 0.821114\n",
      "Bleu_2: 0.698382\n",
      "Bleu_3: 0.574483\n",
      "Bleu_4: 0.457955\n",
      "METEOR: 0.299341\n",
      "ROUGE_L: 0.623049\n",
      "CIDEr: 0.482211\n",
      "Sum: 1.86256\n",
      "seed: 4\n",
      "ave_length: 7.27993\n",
      "novel: 0.213378\n",
      "unique: 0.317726\n",
      "usage: 402\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "- Modify feats_t to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_t (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio0.1.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_T): Text_Embedder()\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (pointer): Pointer(\n",
      "      (attention): ScaledDotProductAttention(\n",
      "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (Wq): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (Wc): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 17190402\n",
      "Trainable Params: 17190402\n",
      "100%|███████████████████████████████████████████| 24/24 [00:59<00:00,  2.47s/it]\n",
      "Bleu_1: 0.82959\n",
      "Bleu_2: 0.703377\n",
      "Bleu_3: 0.574459\n",
      "Bleu_4: 0.45303\n",
      "METEOR: 0.29913\n",
      "ROUGE_L: 0.621185\n",
      "CIDEr: 0.48101\n",
      "Sum: 1.85436\n",
      "seed: 2\n",
      "ave_length: 7.52241\n",
      "novel: 0.218729\n",
      "unique: 0.32408\n",
      "usage: 379\n",
      "1\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "- Modify feats_t to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_t (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_T): Text_Embedder()\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (pointer): Pointer(\n",
      "      (attention): ScaledDotProductAttention(\n",
      "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (Wq): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (Wc): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 17190402\n",
      "Trainable Params: 17190402\n",
      "100%|███████████████████████████████████████████| 24/24 [00:55<00:00,  2.33s/it]\n",
      "Bleu_1: 0.830961\n",
      "Bleu_2: 0.710271\n",
      "Bleu_3: 0.585116\n",
      "Bleu_4: 0.465841\n",
      "METEOR: 0.303047\n",
      "ROUGE_L: 0.631959\n",
      "CIDEr: 0.52431\n",
      "Sum: 1.92516\n",
      "seed: 0\n",
      "ave_length: 7.30201\n",
      "novel: 0.215385\n",
      "unique: 0.324749\n",
      "usage: 406\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "- Modify feats_t to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_t (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_T): Text_Embedder()\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (pointer): Pointer(\n",
      "      (attention): ScaledDotProductAttention(\n",
      "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (Wq): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (Wc): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 17190402\n",
      "Trainable Params: 17190402\n",
      "100%|███████████████████████████████████████████| 24/24 [00:54<00:00,  2.26s/it]\n",
      "Bleu_1: 0.831197\n",
      "Bleu_2: 0.708881\n",
      "Bleu_3: 0.581649\n",
      "Bleu_4: 0.461431\n",
      "METEOR: 0.304825\n",
      "ROUGE_L: 0.631847\n",
      "CIDEr: 0.52238\n",
      "Sum: 1.92048\n",
      "seed: 3\n",
      "ave_length: 7.42542\n",
      "novel: 0.241806\n",
      "unique: 0.344816\n",
      "usage: 429\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "- Modify feats_t to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_t (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_T): Text_Embedder()\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (pointer): Pointer(\n",
      "      (attention): ScaledDotProductAttention(\n",
      "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (Wq): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (Wc): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 17190402\n",
      "Trainable Params: 17190402\n",
      "100%|███████████████████████████████████████████| 24/24 [00:56<00:00,  2.36s/it]\n",
      "Bleu_1: 0.835434\n",
      "Bleu_2: 0.711084\n",
      "Bleu_3: 0.584777\n",
      "Bleu_4: 0.465571\n",
      "METEOR: 0.305983\n",
      "ROUGE_L: 0.632869\n",
      "CIDEr: 0.514236\n",
      "Sum: 1.91866\n",
      "seed: 1\n",
      "ave_length: 7.47391\n",
      "novel: 0.215719\n",
      "unique: 0.318395\n",
      "usage: 386\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "- Modify feats_t to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_t (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_T): Text_Embedder()\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (pointer): Pointer(\n",
      "      (attention): ScaledDotProductAttention(\n",
      "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (Wq): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (Wc): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 17190402\n",
      "Trainable Params: 17190402\n",
      "100%|███████████████████████████████████████████| 24/24 [00:51<00:00,  2.16s/it]\n",
      "Bleu_1: 0.828204\n",
      "Bleu_2: 0.709523\n",
      "Bleu_3: 0.587175\n",
      "Bleu_4: 0.470928\n",
      "METEOR: 0.304954\n",
      "ROUGE_L: 0.635076\n",
      "CIDEr: 0.529185\n",
      "Sum: 1.94014\n",
      "seed: 4\n",
      "ave_length: 7.20602\n",
      "novel: 0.210368\n",
      "unique: 0.314381\n",
      "usage: 413\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "- Modify feats_t to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_t (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio1.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_T): Text_Embedder()\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (pointer): Pointer(\n",
      "      (attention): ScaledDotProductAttention(\n",
      "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (Wq): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (Wc): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 17190402\n",
      "Trainable Params: 17190402\n",
      "100%|███████████████████████████████████████████| 24/24 [00:58<00:00,  2.44s/it]\n",
      "Bleu_1: 0.832008\n",
      "Bleu_2: 0.71012\n",
      "Bleu_3: 0.582461\n",
      "Bleu_4: 0.46103\n",
      "METEOR: 0.303794\n",
      "ROUGE_L: 0.629389\n",
      "CIDEr: 0.51788\n",
      "Sum: 1.91209\n",
      "seed: 2\n",
      "ave_length: 7.46154\n",
      "novel: 0.220401\n",
      "unique: 0.328094\n",
      "usage: 401\n",
      "10\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "- Modify feats_t to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_t (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_T): Text_Embedder()\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (pointer): Pointer(\n",
      "      (attention): ScaledDotProductAttention(\n",
      "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (Wq): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (Wc): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 17190402\n",
      "Trainable Params: 17190402\n",
      "100%|███████████████████████████████████████████| 24/24 [00:55<00:00,  2.33s/it]\n",
      "Bleu_1: 0.833317\n",
      "Bleu_2: 0.714891\n",
      "Bleu_3: 0.589241\n",
      "Bleu_4: 0.467556\n",
      "METEOR: 0.305606\n",
      "ROUGE_L: 0.634633\n",
      "CIDEr: 0.549397\n",
      "Sum: 1.95719\n",
      "seed: 0\n",
      "ave_length: 7.27692\n",
      "novel: 0.233779\n",
      "unique: 0.353846\n",
      "usage: 465\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "- Modify feats_t to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_t (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_T): Text_Embedder()\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (pointer): Pointer(\n",
      "      (attention): ScaledDotProductAttention(\n",
      "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (Wq): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (Wc): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 17190402\n",
      "Trainable Params: 17190402\n",
      "100%|███████████████████████████████████████████| 24/24 [00:56<00:00,  2.34s/it]\n",
      "Bleu_1: 0.832068\n",
      "Bleu_2: 0.710819\n",
      "Bleu_3: 0.584176\n",
      "Bleu_4: 0.462997\n",
      "METEOR: 0.305215\n",
      "ROUGE_L: 0.633246\n",
      "CIDEr: 0.545189\n",
      "Sum: 1.94665\n",
      "seed: 3\n",
      "ave_length: 7.36522\n",
      "novel: 0.258194\n",
      "unique: 0.370234\n",
      "usage: 458\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "- Modify feats_t to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_t (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_T): Text_Embedder()\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (pointer): Pointer(\n",
      "      (attention): ScaledDotProductAttention(\n",
      "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (Wq): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (Wc): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 17190402\n",
      "Trainable Params: 17190402\n",
      "100%|███████████████████████████████████████████| 24/24 [00:58<00:00,  2.44s/it]\n",
      "Bleu_1: 0.837165\n",
      "Bleu_2: 0.717153\n",
      "Bleu_3: 0.591327\n",
      "Bleu_4: 0.470887\n",
      "METEOR: 0.307557\n",
      "ROUGE_L: 0.63566\n",
      "CIDEr: 0.542235\n",
      "Sum: 1.95634\n",
      "seed: 1\n",
      "ave_length: 7.40334\n",
      "novel: 0.231104\n",
      "unique: 0.33913\n",
      "usage: 434\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "- Modify feats_t to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_t (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_T): Text_Embedder()\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (pointer): Pointer(\n",
      "      (attention): ScaledDotProductAttention(\n",
      "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (Wq): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (Wc): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 17190402\n",
      "Trainable Params: 17190402\n",
      "100%|███████████████████████████████████████████| 24/24 [00:56<00:00,  2.37s/it]\n",
      "Bleu_1: 0.829488\n",
      "Bleu_2: 0.712903\n",
      "Bleu_3: 0.591309\n",
      "Bleu_4: 0.473628\n",
      "METEOR: 0.307573\n",
      "ROUGE_L: 0.636256\n",
      "CIDEr: 0.552026\n",
      "Sum: 1.96948\n",
      "seed: 4\n",
      "ave_length: 7.13746\n",
      "novel: 0.229097\n",
      "unique: 0.344147\n",
      "usage: 455\n",
      "init COCO-EVAL scorer\n",
      "- Modify feats_r to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "- Modify feats_t to /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "Dataset Information:\n",
      "- the number of videos in the set `test`: 2990\n",
      "- the number of samples (n_caps_per_video=1): 2990\n",
      "- vocab size is 10547\n",
      "- the maximum sequence length (max_len) is set to 30\n",
      "Modality Information:\n",
      "- loading feats_a (128) from ['/data/video_datasets/MSRVTT/feats/audio_vggish_audioset_fixed60.hdf5']\n",
      "- loading feats_m (2048) from ['/data/video_datasets/MSRVTT/feats/motion_resnext101_kinetics_fixed60.hdf5']\n",
      "- loading feats_i (512) from ['/data/video_datasets/MSRVTT/feats/CLIP_ViT-B-32.hdf5']\n",
      "- loading feats_t (512) from /data/video_datasets/MSRVTT/retrieval/CLIP_ViT-B-32_unique_ratio10.0.hdf5\n",
      "- load feats type: 0\n",
      "- the number of sampled frames is set to 28\n",
      "Model(\n",
      "  (captioner): TransformerSeq2Seq(\n",
      "    (encoder): Embedder(\n",
      "      (Encoder_A): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_M): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_I): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (Encoder_T): Text_Embedder()\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (embedding): Embeddings(\n",
      "        (word_embeddings): Embedding(10547, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(30, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): DecoderLayer(\n",
      "          (intra_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (inter_attention): MultiHeadAttention(\n",
      "            (SDPA): ScaledDotProductAttention(\n",
      "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (ffn): PositionwiseFeedForward(\n",
      "            (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act): ReLU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (pointer): Pointer(\n",
      "      (attention): ScaledDotProductAttention(\n",
      "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (Wq): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (Wc): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (cls_head): NaiveHead(\n",
      "      (tgt_word_prj): Linear(in_features=512, out_features=10547, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "20\n",
      "Total Params: 17190402\n",
      "Trainable Params: 17190402\n",
      "100%|███████████████████████████████████████████| 24/24 [00:58<00:00,  2.44s/it]\n",
      "Bleu_1: 0.836535\n",
      "Bleu_2: 0.71561\n",
      "Bleu_3: 0.588145\n",
      "Bleu_4: 0.465924\n",
      "METEOR: 0.307709\n",
      "ROUGE_L: 0.634582\n",
      "CIDEr: 0.552699\n",
      "Sum: 1.96091\n",
      "seed: 2\n",
      "ave_length: 7.44515\n",
      "novel: 0.241806\n",
      "unique: 0.359866\n",
      "usage: 456\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/retrieval_db_ratio.sh exps/MSRVTT/PointerGen/Base/base_ViT_ami 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52518e00-8b4e-43b7-beb1-e0b006cec706",
   "metadata": {},
   "source": [
    "# analysis on performance drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df2e45ff-4cb5-48ff-a51b-46f0ec9f895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load(root, method, metric='CIDEr', multi=100):\n",
    "    data = []\n",
    "    means = []\n",
    "    for fn, name in zip([\n",
    "        f'retrieval_db_ratio_0.1.csv',\n",
    "        f'retrieval_db_ratio_1.csv',\n",
    "        f'retrieval_db_ratio_10.csv',\n",
    "        'test_result.csv'],\n",
    "        ['0.1%', '1%', '10%', '100%'],\n",
    "    ):   \n",
    "        path = os.path.join(root, fn)\n",
    "        d = pd.read_csv(path)\n",
    "        scores = []\n",
    "        for score in d[metric].tolist():\n",
    "            score *= multi\n",
    "            line = [method, name, score]\n",
    "            data.append(line)\n",
    "            scores.append(score)\n",
    "        means.append(sum(scores) / len(scores))\n",
    "    \n",
    "    return data[::-1], means[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a58530a-c0c1-4f4e-8a72-2d1397118db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1, means1 = load('exps/MSRVTT/Transformer/CARE/base_ViT_VA_VAT', 'CARE (Ours)')\n",
    "data2, means2 = load('exps/MSRVTT/PointerGen/Base/base_ViT_ami', 'PGN')\n",
    "\n",
    "df = pd.DataFrame(data1 + data2, columns=['method', 'ratio', 'CIDEr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ac88ba5-3d99-40a3-a581-96cf2ca3f443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "fontsize=14\n",
    "\n",
    "fig = plt.figure(figsize=(7, 3))\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "ax.set_xlim(0,3)\n",
    "\n",
    "c1 = sns.color_palette()[0]\n",
    "c2 = sns.color_palette()[1]\n",
    "\n",
    "ax.axhline(means1[0], linestyle='dashed', color=c1)\n",
    "ax.axhline(means2[0], linestyle='dashed', color=c2)\n",
    "\n",
    "means = means2\n",
    "c = c2\n",
    "for i in [1,2,3]:\n",
    "    rdrop = (means[0] - means[i]) * 100 / means[0]\n",
    "    ax.annotate('', xy=(i, means[i]), xytext=(i, means[0]), xycoords='data',\n",
    "                arrowprops=dict(facecolor=c, shrink=0.0, width=2, headwidth=8), color=c, fontsize=fontsize)\n",
    "    \n",
    "    ax.text(i, means[0] - 1, '{:.2f}%'.format(rdrop), color=c, fontsize=fontsize)\n",
    "\n",
    "\n",
    "means = means1\n",
    "c = c1\n",
    "for i in [1,2,3]:\n",
    "    rdrop = (means[0] - means[i]) * 100 / means[0]\n",
    "    ax.annotate('{:.2f}%'.format(rdrop), xy=(i, means[i]), xytext=(i, means[0]+0.4), xycoords='data',\n",
    "                arrowprops=dict(facecolor=c, shrink=0.0, width=2, headwidth=8), color=c, fontsize=fontsize)\n",
    "\n",
    "sns.lineplot(x=\"ratio\", y=\"CIDEr\",\n",
    "             hue=\"method\",\n",
    "             data=df, ax=ax)\n",
    "\n",
    "ax.set_ylabel('CIDEr', fontsize=fontsize)\n",
    "ax.set_xlabel('', fontsize=fontsize)\n",
    "ax.legend(fontsize=fontsize)\n",
    "_ = plt.xticks(fontsize=fontsize)\n",
    "_ = plt.yticks(fontsize=fontsize)\n",
    "\n",
    "plt.subplots_adjust(left=0.09, top=0.98, right=0.9, bottom=0.1)\n",
    "\n",
    "# plt.savefig('retrieval_db_ratio.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fd2f55-4306-4835-ab96-59be373e786e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
